{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "https://ithelp.ithome.com.tw/articles/10223922\n",
    "<br>\n",
    "https://github.com/johngilbert2000/sentiment140_with_fastai/blob/master/TF_NLP_sentiment140.ipynb\n",
    "<br>\n",
    "https://blog.csdn.net/xc_zhou/article/details/88669669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/training.1600000.processed.noemoticon.csv\", usecols=[0,5], header=None, names=['label','text'],encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "1599995      4  Just woke up. Having no school is the best fee...\n",
       "1599996      4  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997      4  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998      4  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999      4  happy #charitytuesday @theNSPCC @SparksCharity..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1546285</th>\n",
       "      <td>2</td>\n",
       "      <td>@Super_fresh Your welcome.....  I caught it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938301</th>\n",
       "      <td>2</td>\n",
       "      <td>@jophillips Origin of Symmetry is their best, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216763</th>\n",
       "      <td>2</td>\n",
       "      <td>@emmao414 Mornin! I was super-tired this morn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424033</th>\n",
       "      <td>0</td>\n",
       "      <td>my days are all mixed up  i thought today was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590526</th>\n",
       "      <td>0</td>\n",
       "      <td>@chipcoffey Can you do me a favor and pray for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "1546285      2       @Super_fresh Your welcome.....  I caught it!\n",
       "938301       2  @jophillips Origin of Symmetry is their best, ...\n",
       "1216763      2  @emmao414 Mornin! I was super-tired this morn ...\n",
       "424033       0  my days are all mixed up  i thought today was ...\n",
       "590526       0  @chipcoffey Can you do me a favor and pray for..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPARE DATA\n",
    "\n",
    "# Randomize data\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "\n",
    "# For Binary Classification: Convert Labels to 0 and 1 \n",
    "# df.loc[df['label'] == 4, 'label'] = 1\n",
    "\n",
    "# Classfication: Covert all labels {negative = 0, neutral = 1,positive = 2}\n",
    "df.loc[df['label'] == 4, 'label'] = 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE SUBSETS\n",
    "splits = 5\n",
    "# Equal length subsets of original dataframe\n",
    "cut_indices = [int(i*(1/splits)*len(df)) for i in range(0,splits+1)] # indices where df is to be cut\n",
    "segment_indices = zip(cut_indices[:-1], cut_indices[1:]) # indices for each cut segment\n",
    "valids = [df[begin:end] for begin,end in segment_indices] # subsets each to be used as validation sets\n",
    "\n",
    "# Training sets for each validation set in valids\n",
    "trains = [pd.concat(valids[1:], axis=0)]\n",
    "for n in range(1,splits):\n",
    "    trains += [pd.concat(valids[:n]+valids[n+1:], axis=0)] # (all sets except for set n in range(splits))\n",
    "\n",
    "# Validation and Training Sets to be used\n",
    "validation = valids[0]\n",
    "training = trains[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99930625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a mean close to 0.5 for labels indicates a well balanced dataset\n",
    "validation['label'].describe()['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>789494</th>\n",
       "      <td>0</td>\n",
       "      <td>@Krankitupmag LOL mentally yes but physically ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70245</th>\n",
       "      <td>0</td>\n",
       "      <td>@jason_mraz so sad I got to Indie today at 3:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414313</th>\n",
       "      <td>0</td>\n",
       "      <td>Head hurts fro holding back the tears of seein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117470</th>\n",
       "      <td>2</td>\n",
       "      <td>getting ready 2 go out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338472</th>\n",
       "      <td>2</td>\n",
       "      <td>@Brantanamo there's nothing wrong with being a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "789494       0  @Krankitupmag LOL mentally yes but physically ...\n",
       "70245        0  @jason_mraz so sad I got to Indie today at 3:0...\n",
       "414313       0  Head hurts fro holding back the tears of seein...\n",
       "1117470      2                            getting ready 2 go out \n",
       "1338472      2  @Brantanamo there's nothing wrong with being a..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZE DATASET\n",
    "\n",
    "vocab_size = 10000 #5000 # 10000\n",
    "\n",
    "text = training['text'].to_numpy()\n",
    "\n",
    "tok = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token='<unk>')\n",
    "\n",
    "tok.fit_on_texts(text)\n",
    "\n",
    "tok.word_index['<pad>'] = 0\n",
    "tok.index_word[0] = '<pad>'\n",
    "\n",
    "# pad vectors to maxlength\n",
    "train_text = training['text'].to_numpy()\n",
    "train_seqs = tok.texts_to_sequences(train_text)\n",
    "maxlength = max(len(i) for i in train_seqs)\n",
    "train_seqs = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, maxlen=maxlength, padding='post')\n",
    "\n",
    "print(maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = training['label'].to_numpy().flatten()\n",
    "train_labels = training['label'].to_numpy()\n",
    "train_labels = to_categorical(train_labels, num_classes=3, dtype='uint8')\n",
    "\n",
    "# pad vectors to maxlength (don't calculate automatically, or valid set will be of different size)\n",
    "valid_text = validation['text'].to_numpy()\n",
    "valid_seqs = tok.texts_to_sequences(valid_text)\n",
    "valid_seqs = tf.keras.preprocessing.sequence.pad_sequences(valid_seqs, maxlen=maxlength, padding='post')\n",
    "\n",
    "# valid_labels = validation['label'].to_numpy().flatten()\n",
    "valid_labels = validation['label'].to_numpy()\n",
    "valid_labels = to_categorical(valid_labels, num_classes=3, dtype='uint8')\n",
    "\n",
    "# Use lowest possible types to speed up training\n",
    "train_seqs = train_seqs.astype('uint16')\n",
    "valid_seqs = valid_seqs.astype('uint16')\n",
    "# train_labels = train_labels.astype('bool')\n",
    "# valid_labels = valid_labels.astype('bool') # uint8 or bool?\n",
    "\n",
    "# Convert to TF dataset format\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_seqs,train_labels))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((valid_seqs,valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import numbers\n",
    "import os\n",
    "import unittest\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USEFUL FUNCTIONS\n",
    "\n",
    "def word2vec(words):\n",
    "    if isinstance(words, str):\n",
    "        \"Takes a string of words and returns a list of corresponding integers\"\n",
    "        seq = tok.texts_to_sequences([words])\n",
    "        return np.array(seq).flatten().tolist()\n",
    "    elif isinstance(words, typing.Iterable):\n",
    "        \"Takes a list of strings and returns a list of sequences (lists of corresponding integers)\"\n",
    "        return tok.texts_to_sequences(words)\n",
    "    else:\n",
    "        raise ValueError(f'Words were of type {type(words)} but should be either a string or list of strings')\n",
    "        \n",
    "\n",
    "def vec2word(vec:typing.Iterable[typing.Any]):\n",
    "    if isinstance(vec[0], numbers.Number):\n",
    "        \"Takes a list of ints and returns a corresponding string\"\n",
    "        return \" \".join([list(tok.word_index.keys())[i-1] for i in vec])\n",
    "    elif isinstance(vec[0], typing.Iterable):\n",
    "        \"Takes an array of sequences (i.e., a 2d array) and returns an array of strings\"\n",
    "        return [vec2word(i) for i in vec]\n",
    "    else:\n",
    "        raise ValueError( f'Input list should contain either ints or lists of ints, not {type(vec[0])}')\n",
    "\n",
    "def vec2word_no_pad(vec:typing.Iterable[typing.Any]):\n",
    "    \"Removes padding and converts vectors of ints to strings\"\n",
    "    if isinstance(vec[0], numbers.Number):\n",
    "        \"Takes a list of ints and returns a corresponding string\"\n",
    "        return \" \".join([list(tok.word_index.keys())[i-1] for i in vec if i != 0])\n",
    "    elif isinstance(vec[0], typing.Iterable):\n",
    "        \"Takes an array of sequences (i.e., a 2d array) and returns an array of strings\"\n",
    "        return [vec2word(i) for i in vec if i != 0]\n",
    "    else:\n",
    "        raise ValueError( f'Input list should contain either ints or lists of ints, not {type(vec[0])}')\n",
    "\n",
    "def show_batch(ds):\n",
    "    \"Takes a tensorflow dataset and returns a batch as a dataframe, with labels shown without padding\"\n",
    "    batch_vecs, batch_targets = next(iter(ds.batch(1)))  # iterate through dataset batches\n",
    "    batch_vecs, batch_targets = np.array(batch_vecs)[0], np.array(batch_targets)[0]  # convert tf batch to np array & reduce dimension by 1\n",
    "    return pd.DataFrame(zip(batch_vecs, [vec2word_no_pad(arr) for arr in batch_vecs], batch_targets), columns=['word_vec','text','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 64, 96, 128, 160, 192, 224, 256, 288]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[32*i for i in range(1,10)] # Choose a multiple of 32 for embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 10000 594964 2500 2 312\n"
     ]
    }
   ],
   "source": [
    "# TRAINING PARAMETERS\n",
    "\n",
    "# Calculates the max_length, which can be used to store the attention weights\n",
    "maxlength = max(len(i) for i in train_seqs)\n",
    "total_vocab_size = len(tok.word_index) # no need to add +1, word_index includes <pad>\n",
    "batch_size = 512 # 256 # 128 # 64\n",
    "buffer_size = 1000 # 500 # 1000\n",
    "embedding_dim = 64 # 32 # 64 # 128 # 256\n",
    "num_steps = len(train_text) // batch_size\n",
    "epochs = num_steps // buffer_size\n",
    "val_steps = len(valid_seqs) // batch_size // epochs\n",
    "learning_rate = 0.001 * 8\n",
    "\n",
    "print(maxlength, vocab_size, total_vocab_size, num_steps, epochs, val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 52), (None, 3)), types: (tf.uint16, tf.uint8)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SHUFFLE AND BATCH\n",
    "\n",
    "train_batch = train_ds.shuffle(buffer_size).batch(batch_size)\n",
    "valid_batch = valid_ds.shuffle(buffer_size).batch(batch_size)\n",
    "train_prefetch = train_batch.prefetch(buffer_size=tf.data.AUTOTUNE) # prefetch speeds up training\n",
    "valid_prefetch = valid_batch.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "valid_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_batch(valid_prefetch) # Note: determining <unk> words is a bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=maxlength),\n",
    "    Conv1D(filters=16, kernel_size=3, padding='valid'),\n",
    "    MaxPool1D(),\n",
    "#   Dense(32,activation='relu'),\n",
    "    Bidirectional(GRU(embedding_dim//2, return_sequences=True)), # embedding_dim//2\n",
    "    Bidirectional(GRU(embedding_dim//2, return_sequences=True)),\n",
    "    Bidirectional(GRU(embedding_dim//2, return_sequences=False)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid') #3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', # categorical_crossentropy for multilabel classification\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_prefetch,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_prefetch, \n",
    "    validation_steps=val_steps,\n",
    "    steps_per_epoch=buffer_size,\n",
    "    callbacks = [] # [tf.keras.callbacks.ReduceLROnPlateau()] # cp_callback not used\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super(Linear, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=maxlength),\n",
    "    Bidirectional(LSTM(64,  return_sequences=True)),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', # categorical_crossentropy for multilabel classification\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 40s 34ms/step - loss: 0.5575 - accuracy: 0.7114 - val_loss: 0.4220 - val_accuracy: 0.8044\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.4259 - accuracy: 0.8057 - val_loss: 0.4051 - val_accuracy: 0.8132\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(\n",
    "    train_prefetch,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_prefetch,\n",
    "    validation_steps=val_steps,\n",
    "    steps_per_epoch=buffer_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_7/embeddings:0' shape=(10000, 64) dtype=float32, numpy=\n",
       " array([[-0.02485519,  0.04324025, -0.00568551, ..., -0.00574601,\n",
       "         -0.04451542, -0.0130531 ],\n",
       "        [ 0.02046304,  0.00856596,  0.00592808, ..., -0.02653407,\n",
       "          0.02381715, -0.02713521],\n",
       "        [ 0.0463605 , -0.0442538 , -0.02002962, ...,  0.00202338,\n",
       "          0.02146444,  0.03020327],\n",
       "        ...,\n",
       "        [ 0.01855123,  0.02055471,  0.04204352, ...,  0.02218182,\n",
       "         -0.00423261, -0.04469874],\n",
       "        [ 0.00067336, -0.03011259, -0.02247182, ..., -0.03586928,\n",
       "         -0.0445512 ,  0.02848769],\n",
       "        [ 0.00945091,  0.02293407,  0.03152895, ..., -0.02468808,\n",
       "         -0.02930619,  0.04416488]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_14/forward_lstm_14/lstm_cell_43/kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
       " array([[ 0.10738212,  0.09106629, -0.12615612, ...,  0.01291603,\n",
       "         -0.03119817,  0.08497344],\n",
       "        [ 0.11975107,  0.0686501 , -0.06333651, ..., -0.03790931,\n",
       "          0.13406837, -0.02628689],\n",
       "        [ 0.02203134,  0.02367479,  0.10312739, ...,  0.09116139,\n",
       "          0.04357761,  0.00865683],\n",
       "        ...,\n",
       "        [-0.10447094, -0.07215493,  0.00276715, ..., -0.04211765,\n",
       "          0.06192856,  0.01468907],\n",
       "        [ 0.11498761, -0.06162546,  0.01538618, ..., -0.12191249,\n",
       "          0.11722744, -0.08964214],\n",
       "        [-0.11482631,  0.08933812, -0.08829803, ..., -0.06954874,\n",
       "          0.05005729,  0.08948676]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_14/forward_lstm_14/lstm_cell_43/recurrent_kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
       " array([[ 0.06957102,  0.00957646, -0.05794969, ..., -0.13449769,\n",
       "         -0.07136278,  0.03452855],\n",
       "        [ 0.00036123,  0.02336121, -0.10505421, ..., -0.07207618,\n",
       "         -0.12256249,  0.00207211],\n",
       "        [ 0.00878807, -0.00534068,  0.04524708, ...,  0.10999868,\n",
       "          0.01291057,  0.06161437],\n",
       "        ...,\n",
       "        [ 0.0967162 ,  0.04430119, -0.00384378, ..., -0.06472486,\n",
       "         -0.0195285 , -0.00221818],\n",
       "        [ 0.01066866, -0.02571387, -0.01096914, ...,  0.15296589,\n",
       "          0.0123977 ,  0.06178252],\n",
       "        [ 0.10312293,  0.11625528, -0.03271176, ...,  0.03913951,\n",
       "          0.06664391, -0.05210675]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_14/forward_lstm_14/lstm_cell_43/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_14/backward_lstm_14/lstm_cell_44/kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
       " array([[ 0.11156809, -0.02699757,  0.04595186, ...,  0.08449353,\n",
       "          0.07516542, -0.11003301],\n",
       "        [ 0.10271728, -0.02109754, -0.00226715, ...,  0.12690488,\n",
       "          0.06565188,  0.10514022],\n",
       "        [ 0.09172249,  0.00054801, -0.03609598, ..., -0.04840049,\n",
       "         -0.07174682, -0.05557   ],\n",
       "        ...,\n",
       "        [ 0.09652343,  0.11918917,  0.12991595, ...,  0.01936024,\n",
       "          0.08848327, -0.11515966],\n",
       "        [-0.02661286,  0.1234602 ,  0.03513789, ..., -0.09029908,\n",
       "          0.05151245,  0.10111928],\n",
       "        [ 0.01104961, -0.10384588,  0.10368027, ...,  0.07876298,\n",
       "          0.08364886, -0.0147002 ]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_14/backward_lstm_14/lstm_cell_44/recurrent_kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
       " array([[-0.01176405, -0.0078522 ,  0.11111858, ..., -0.09901831,\n",
       "         -0.08328615, -0.01071063],\n",
       "        [-0.06344268,  0.07056439,  0.05103075, ...,  0.04272599,\n",
       "         -0.02245434, -0.01210609],\n",
       "        [-0.06626552, -0.01747192, -0.03896928, ..., -0.06234952,\n",
       "          0.03177332, -0.0146453 ],\n",
       "        ...,\n",
       "        [ 0.01885529,  0.06191229,  0.1396726 , ..., -0.078446  ,\n",
       "         -0.09384215, -0.03601278],\n",
       "        [-0.09506605, -0.08849553,  0.03924067, ...,  0.01367134,\n",
       "         -0.01735095, -0.02982193],\n",
       "        [ 0.03914233,  0.05166284,  0.04915884, ...,  0.0844987 ,\n",
       "         -0.05854361, -0.03239272]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_14/backward_lstm_14/lstm_cell_44/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_15/forward_lstm_15/lstm_cell_46/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
       " array([[ 1.52897641e-01,  8.39029998e-02,  5.07272035e-02, ...,\n",
       "         -9.29459333e-02,  9.13535058e-02,  9.37952995e-02],\n",
       "        [ 3.95657122e-02,  1.98715776e-02, -4.20808792e-05, ...,\n",
       "         -7.12186098e-04, -9.82840955e-02,  1.32654116e-01],\n",
       "        [-2.23309249e-02,  8.98409635e-02,  1.26268610e-01, ...,\n",
       "          1.43228933e-01,  4.80511039e-02, -5.30673712e-02],\n",
       "        ...,\n",
       "        [ 5.50289005e-02, -4.38990965e-02, -1.09705791e-01, ...,\n",
       "         -1.00685626e-01, -7.56687969e-02, -4.52857018e-02],\n",
       "        [ 3.27284485e-02,  1.34487167e-01,  3.53903770e-02, ...,\n",
       "          9.75241810e-02,  4.77683842e-02,  1.48404539e-02],\n",
       "        [-6.49052411e-02,  8.89141858e-03,  1.36348382e-01, ...,\n",
       "         -6.54849783e-02,  1.36529192e-01,  1.33197010e-03]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_15/forward_lstm_15/lstm_cell_46/recurrent_kernel:0' shape=(32, 128) dtype=float32, numpy=\n",
       " array([[-0.10500252, -0.05535435,  0.22692263, ...,  0.01650014,\n",
       "         -0.04945283,  0.08964065],\n",
       "        [-0.01248151, -0.04758859, -0.08327421, ..., -0.08065502,\n",
       "         -0.00998558, -0.00600574],\n",
       "        [ 0.08526122,  0.0067037 , -0.06012973, ..., -0.25555155,\n",
       "          0.07330565, -0.08253352],\n",
       "        ...,\n",
       "        [ 0.00741111, -0.11301439, -0.01731418, ...,  0.07556979,\n",
       "         -0.10479956,  0.04543169],\n",
       "        [-0.02236985,  0.01451806,  0.02545765, ..., -0.05761098,\n",
       "          0.02390379,  0.1315315 ],\n",
       "        [ 0.05748577,  0.12149411, -0.08650979, ..., -0.07890908,\n",
       "          0.05162778, -0.00074488]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_15/forward_lstm_15/lstm_cell_46/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_15/backward_lstm_15/lstm_cell_47/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
       " array([[-0.10138406, -0.05211329, -0.1174238 , ..., -0.08855459,\n",
       "          0.02498482,  0.14435165],\n",
       "        [-0.13003515, -0.14035803, -0.01597229, ...,  0.13462152,\n",
       "          0.03192443,  0.03166342],\n",
       "        [-0.13480338, -0.05329269, -0.0316295 , ...,  0.12237759,\n",
       "          0.06664681, -0.0163805 ],\n",
       "        ...,\n",
       "        [-0.12379496,  0.07948431, -0.04779696, ...,  0.1415021 ,\n",
       "          0.00975527, -0.01701477],\n",
       "        [ 0.07130523,  0.13467883, -0.04070529, ...,  0.02719954,\n",
       "          0.06296967,  0.14364879],\n",
       "        [-0.06385429, -0.07874011, -0.10725049, ...,  0.02742483,\n",
       "         -0.14066066,  0.10926534]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_15/backward_lstm_15/lstm_cell_47/recurrent_kernel:0' shape=(32, 128) dtype=float32, numpy=\n",
       " array([[-1.64674520e-02, -3.32537224e-03,  5.41479178e-02, ...,\n",
       "         -1.18030712e-01, -1.15215234e-01,  1.33440942e-01],\n",
       "        [-8.36201850e-03, -8.79750848e-02,  1.45578161e-01, ...,\n",
       "         -1.23766504e-01, -8.83023590e-02,  7.06057623e-02],\n",
       "        [ 1.53730020e-01, -1.38638942e-02,  7.02109933e-03, ...,\n",
       "          1.60504133e-04, -2.00645830e-02,  6.40624538e-02],\n",
       "        ...,\n",
       "        [ 1.86406188e-02, -6.29970850e-03, -1.43422438e-02, ...,\n",
       "         -4.72199954e-02,  8.53225067e-02, -2.62788177e-01],\n",
       "        [-8.68384466e-02, -1.14434563e-01,  7.70701021e-02, ...,\n",
       "         -9.84829962e-02,  1.89478382e-01, -3.36278602e-02],\n",
       "        [-5.13030663e-02,  1.02138110e-01,  1.65322721e-02, ...,\n",
       "         -9.20213759e-02,  2.49650329e-02,  1.28002465e-01]], dtype=float32)>,\n",
       " <tf.Variable 'bidirectional_15/backward_lstm_15/lstm_cell_47/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_12/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[ 0.06013463, -0.14704672, -0.18208861, ..., -0.15368575,\n",
       "          0.15720432, -0.09415398],\n",
       "        [-0.14653629, -0.02642693, -0.10687701, ...,  0.09448303,\n",
       "         -0.04513933, -0.14551625],\n",
       "        [-0.21464847,  0.13567115, -0.01574859, ..., -0.07183041,\n",
       "         -0.16711834,  0.15493865],\n",
       "        ...,\n",
       "        [-0.09144035,  0.08092885,  0.20465021, ...,  0.21198969,\n",
       "         -0.00389415,  0.16089864],\n",
       "        [-0.03074884, -0.03667937, -0.04661688, ...,  0.09398006,\n",
       "          0.16628675, -0.02210636],\n",
       "        [ 0.07120974, -0.02886206, -0.19794731, ..., -0.00397441,\n",
       "          0.00960168, -0.19884156]], dtype=float32)>,\n",
       " <tf.Variable 'dense_12/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_13/kernel:0' shape=(64, 3) dtype=float32, numpy=\n",
       " array([[ 1.10214084e-01,  2.89607942e-01,  4.15483117e-02],\n",
       "        [-2.61368692e-01,  7.91378617e-02, -1.55337334e-01],\n",
       "        [ 2.25433767e-01,  1.80973172e-01,  2.46832013e-01],\n",
       "        [-2.81832129e-01, -1.17451638e-01, -1.72103062e-01],\n",
       "        [-7.23935217e-02, -2.70374715e-02, -1.08377323e-01],\n",
       "        [-1.70961499e-01, -5.87317795e-02, -2.26897031e-01],\n",
       "        [-2.76873767e-01, -2.80485511e-01, -8.46031457e-02],\n",
       "        [ 2.71391869e-03,  1.56393647e-01,  1.32145435e-01],\n",
       "        [-2.07996160e-01,  3.62392962e-02, -2.16176644e-01],\n",
       "        [-3.49467993e-03, -1.41986445e-01, -2.92405248e-01],\n",
       "        [-1.18365884e-03, -1.44721404e-01,  1.25581741e-01],\n",
       "        [ 2.63755381e-01,  2.70725965e-01, -1.24513894e-01],\n",
       "        [-4.76884842e-02, -8.96152854e-03, -4.59834933e-03],\n",
       "        [-5.55334091e-02, -4.86096740e-03, -2.49948889e-01],\n",
       "        [-6.40648603e-02,  2.33656526e-01,  2.93377280e-01],\n",
       "        [-1.12500548e-01,  1.21020585e-01, -9.41544175e-02],\n",
       "        [-2.80222595e-01,  5.92403412e-02,  1.58751160e-01],\n",
       "        [ 1.85146093e-01,  2.69098938e-01, -2.20244095e-01],\n",
       "        [-2.03062132e-01,  9.58718956e-02,  3.12764943e-02],\n",
       "        [ 1.88214481e-02, -1.44750312e-01, -2.56223172e-01],\n",
       "        [ 2.64467657e-01,  2.92869687e-01,  1.00328624e-02],\n",
       "        [-5.92943579e-02,  1.61613643e-01,  1.84802681e-01],\n",
       "        [ 1.65204197e-01, -1.49395764e-02, -2.40650475e-02],\n",
       "        [-8.74071717e-02, -1.18757188e-02, -2.13476285e-01],\n",
       "        [-6.75309151e-02,  1.73257738e-01,  2.66864121e-01],\n",
       "        [ 2.43560314e-01,  3.08008194e-02,  8.17842782e-02],\n",
       "        [ 2.01831400e-01, -1.23375043e-01, -1.92084119e-01],\n",
       "        [-2.27811486e-01, -1.70001879e-01,  3.50226760e-02],\n",
       "        [-8.11412930e-03,  2.72189558e-01, -7.94088393e-02],\n",
       "        [-1.12083882e-01, -2.33397350e-01, -5.23969829e-02],\n",
       "        [ 6.08447194e-02, -1.36950970e-01, -1.14166588e-01],\n",
       "        [-3.58622074e-02,  1.56232953e-01,  3.87757719e-02],\n",
       "        [-1.76381767e-01, -2.26217300e-01,  1.41976893e-01],\n",
       "        [-1.95065647e-01,  2.12866008e-01,  1.42716348e-01],\n",
       "        [-2.70903111e-04, -2.99103111e-01,  2.08546519e-02],\n",
       "        [ 1.82559371e-01,  1.33350044e-01, -2.36570597e-01],\n",
       "        [-2.67519355e-02, -2.27418572e-01, -1.38754904e-01],\n",
       "        [-1.81016624e-01, -1.64812997e-01,  3.14890444e-02],\n",
       "        [ 1.58378810e-01, -4.10875678e-02,  1.87777430e-01],\n",
       "        [ 2.82487750e-01,  1.43501371e-01,  1.49622977e-01],\n",
       "        [ 2.05262482e-01, -8.90293717e-03,  2.87186146e-01],\n",
       "        [ 2.87324131e-01, -8.50418210e-03, -2.73445308e-01],\n",
       "        [-5.78877330e-03, -2.31510133e-01, -8.94857347e-02],\n",
       "        [-5.83509952e-02, -2.51860976e-01,  2.09671140e-01],\n",
       "        [-1.72200024e-01, -2.84155339e-01, -7.21284002e-02],\n",
       "        [-2.91900098e-01,  1.50457114e-01,  8.89773667e-02],\n",
       "        [-5.63477725e-02, -8.42459053e-02,  1.06272995e-01],\n",
       "        [ 2.88598359e-01, -2.39682913e-01, -1.62140608e-01],\n",
       "        [-1.14726380e-01, -2.02449620e-01, -1.82188720e-01],\n",
       "        [ 2.91831613e-01,  1.75353587e-01,  2.74029076e-01],\n",
       "        [-1.27321556e-01, -1.90202758e-01, -2.60724694e-01],\n",
       "        [-1.25656590e-01,  1.87579751e-01,  5.29878736e-02],\n",
       "        [-2.57337630e-01, -4.19991016e-02,  1.97863340e-01],\n",
       "        [-9.64681506e-02,  6.74501359e-02, -1.68288827e-01],\n",
       "        [ 2.47258306e-01, -5.13346940e-02, -9.18762982e-02],\n",
       "        [ 2.25382507e-01, -1.99139118e-04,  2.90586174e-01],\n",
       "        [-1.39441416e-01,  2.38095760e-01, -2.06570774e-01],\n",
       "        [-1.71836719e-01, -2.01384187e-01, -2.40383968e-01],\n",
       "        [-2.33723044e-01, -2.42410094e-01,  8.96796584e-02],\n",
       "        [-2.29843378e-01,  2.12427437e-01, -6.65172935e-03],\n",
       "        [-2.23449737e-01, -4.14001942e-03, -3.26931775e-02],\n",
       "        [ 1.61774933e-01,  2.27846324e-01, -2.25419417e-01],\n",
       "        [-1.57857969e-01,  1.17911965e-01, -2.45785624e-01],\n",
       "        [ 2.66628027e-01,  3.23216617e-02,  3.63539457e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_13/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = model_2.trainable_variables\n",
    "tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.embeddings.Embedding'>\n",
      "<class 'tensorflow.python.keras.layers.wrappers.Bidirectional'>\n",
      "<class 'tensorflow.python.keras.layers.wrappers.Bidirectional'>\n",
      "<class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "<class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "<class 'tensorflow.python.keras.layers.core.Dense'>\n"
     ]
    }
   ],
   "source": [
    "# Check whether the manual weight modifications work-\n",
    "for layer in model_2.layers:\n",
    "    print(type(layer))\n",
    "#     print(layer.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(valid_prefetch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata_df = pd.read_csv(\"dataset/testdata.manual.2009.06.14.csv\", usecols=[0,5], header=None, names=['label','text'],encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classfication: Covert all labels {negative = 0, neutral = 1,positive = 2}\n",
    "testdata_df.loc[testdata_df['label'] == 2, 'label'] = 1\n",
    "testdata_df.loc[testdata_df['label'] == 4, 'label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>@sportsguy33 Time Warner = epic fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "      <td>Lawson to head Newedge Hong Kong http://bit.ly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1</td>\n",
       "      <td>Weird Piano Guitar House in China! http://u2s....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "      <td>Send us your GM/Chevy photos http://tinyurl.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>I know. How sad is that?  RT @caseymercier: 1s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1</td>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "398      0               @sportsguy33 Time Warner = epic fail\n",
       "399      1  Lawson to head Newedge Hong Kong http://bit.ly...\n",
       "400      1  Weird Piano Guitar House in China! http://u2s....\n",
       "401      1  Send us your GM/Chevy photos http://tinyurl.co...\n",
       "402      0  I know. How sad is that?  RT @caseymercier: 1s...\n",
       "..     ...                                                ...\n",
       "493      1  Ask Programming: LaTeX or InDesign?: submitted...\n",
       "494      0  On that note, I hate Word. I hate Pages. I hat...\n",
       "495      2  Ahhh... back in a *real* text editing environm...\n",
       "496      0  Trouble in Iran, I see. Hmm. Iran. Iran so far...\n",
       "497      0  Reading the tweets coming out of Iran... The w...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata_df.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = testdata_df['text'].to_numpy()\n",
    "test_seqs = tok.texts_to_sequences(test_text)\n",
    "test_seqs = tf.keras.preprocessing.sequence.pad_sequences(test_seqs, maxlen=maxlength, padding='post')\n",
    "\n",
    "test_labels = testdata_df['label'].to_numpy()\n",
    "test_labels = to_categorical(test_labels, num_classes=3, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@johncmayer is Bobby Flay joining you?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text[488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'johncmayer is bobby <unk> joining you'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2word_no_pad(test_seqs[488])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model_2.predict(test_seqs), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2,\n",
       "       0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0,\n",
       "       0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2,\n",
       "       0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0,\n",
       "       0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2,\n",
       "       2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0,\n",
       "       2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0,\n",
       "       0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0,\n",
       "       0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
       "       0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2,\n",
       "       2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0,\n",
       "       0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(498):\n",
    "    print(\"IDX: {}, ANS:{}, PREDICT:{}\".format(x, test_labels[x], rs[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION FUNCTIONS\n",
    "\n",
    "# maxlength = 118\n",
    "\n",
    "# def sentiment(num):\n",
    "#     \"Converts a float into the corresponding sentiment label\"\n",
    "#     if num < 0.40: return 'negative'\n",
    "#     if num > 0.60: return 'positive'\n",
    "#     return 'neutral'\n",
    "\n",
    "def sentiment(num):\n",
    "    \"Converts a float into the corresponding sentiment label\"\n",
    "    if num < 0.40: return 0\n",
    "    if num > 0.60: return 4\n",
    "    return 2\n",
    "\n",
    "\n",
    "def give_sentiment(sent):\n",
    "    \"Prints given sentences with their predicted sentiments\"\n",
    "    if isinstance(sent, str):\n",
    "        spaces = len(str)\n",
    "        s = word2vec([sent])\n",
    "        s = tf.keras.preprocessing.sequence.pad_sequences(s, maxlen=maxlength, padding='post').astype('uint16')\n",
    "        val = model_2.predict(s)[0]\n",
    "        res = sentiment(val)\n",
    "        print(\"\\n\")\n",
    "        print(f\"{sent}\", \" \"*(5+spaces-len(sent)), \"|\", \" \"*10, f\" {res} ({val[0]:.2f})\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    elif isinstance(sent, typing.Iterable):\n",
    "        spaces = max([len(i) for i in sent])\n",
    "        s = word2vec(sent)\n",
    "        s = tf.keras.preprocessing.sequence.pad_sequences(s, maxlen=maxlength, padding='post').astype('uint16')\n",
    "        vals = [i for i in model_2.predict(s)]\n",
    "        res = [sentiment(i[0]) for i in vals]\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        for (sentence, result, val) in zip(sent, res, vals):\n",
    "\n",
    "            print(f\"{sentence}\", \" \"*(spaces-len(sentence)), \"|\", \" \"*4, f\" {result}  ({val[0]:.2f})\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise TypeError\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\"Ask Programming LaTeX or InDesign submitted by calcio1\"]\n",
    "\n",
    "give_sentiment(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for x in rs:\n",
    "    pred_list.append(sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in range(len(pred_list)):\n",
    "    if pred_list[x] == test_labels[x]:\n",
    "        count = count + 1\n",
    "\n",
    "count / len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
