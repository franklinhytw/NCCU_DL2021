{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(type_text):\n",
    "    f_data = open('../emnist/emnist-byclass-'+ type_text + '-images-idx3-ubyte')\n",
    "    f_data = np.fromfile(file=f_data, dtype=np.uint8)\n",
    "    f_data = f_data[16:].reshape(-1, 28, 28).astype(np.uint8)\n",
    "    f_label = open('../emnist/emnist-byclass-'+ type_text + '-labels-idx1-ubyte')\n",
    "    f_label = np.fromfile(file=f_label, dtype=np.uint8)\n",
    "    f_label = f_label[8:].reshape(-1).astype(np.uint8)\n",
    "    return f_data, f_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = load_data('train')\n",
    "test_data, test_label = load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 697932, Test data size: 116323\n"
     ]
    }
   ],
   "source": [
    "# Validation data size: Train=697,932, Test=116,323\n",
    "print(\"Train data size: {train}, Test data size: {test}\".format(train=len(train_data), test=len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = to_categorical(train_label, num_classes=62, dtype='uint8')\n",
    "test_label = to_categorical(test_label, num_classes=62, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"log/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Training Data\n",
    "train_data = train_data.reshape((train_data.shape[0], 28, 28, 1))\n",
    "\n",
    "# Reshape Testing Data\n",
    "test_data = test_data.reshape((test_data.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(697932, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(697932, 62)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# =====add layer=====\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(62, activation = \"softmax\"))\n",
    "# ===================\n",
    "\n",
    "# # Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "plot_model(model_3, to_file=\"image/baseline_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: Test Data Accuracy = 0.87\n",
    "model.fit(train_data, train_label, epochs=20, batch_size=512, verbose=2, shuffle=True, validation_split=0.1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/baseline_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model_2 = Sequential()\n",
    "\n",
    "# =====add layer=====\n",
    "model_2.add(Conv2D(6, kernel_size=5, strides=1, padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "model_2.add(Conv2D(16, kernel_size=5, strides=1, padding = 'Same', activation ='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "model_2.add(AveragePooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "model_2.add(Dropout(0.3))\n",
    "\n",
    "model_2.add(Conv2D(32, kernel_size=5, strides=1, padding = 'Same', activation ='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "model_2.add(Conv2D(64, kernel_size=5, strides=1, padding = 'Same', activation ='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(AveragePooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "model_2.add(Dropout(0.3))\n",
    "\n",
    "model_2.add(Conv2D(128, kernel_size=5, strides=1, padding = 'Same',  activation ='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.3))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "\n",
    "model_2.add(Dense(256, activation = \"relu\"))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Dense(62, activation = \"softmax\"))\n",
    "# ===================\n",
    "\n",
    "# # Compile model\n",
    "opt = Adam(learning_rate=0.005)\n",
    "model_2.compile(loss='CategoricalCrossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model_2.summary()\n",
    "plot_model(model_3, to_file=\"image/improvement_1_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(train_data, train_label, epochs=30, verbose=2, batch_size=512, shuffle=True, validation_split=0.1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('saved_model/improvement_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_2 = tf.keras.models.load_model('saved_model/improvement_1_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_2.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model_2.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRAW confusion-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = np.argmax(pred_Y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_Y = np.argmax(test_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "axis_labels = [] # labels for axis\n",
    "\n",
    "# push 0~9\n",
    "for d in string.digits:\n",
    "    axis_labels.append(d)\n",
    "\n",
    "# push A~Z\n",
    "for uc in string.ascii_uppercase:\n",
    "    axis_labels.append(uc)\n",
    "\n",
    "# push a~z\n",
    "for ul in string.ascii_lowercase:\n",
    "    axis_labels.append(ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(80,60))         # Sample figsize in inches\n",
    "fig = sns.heatmap(conf_matrix, annot=True, fmt='d', linewidths=.5, ax=ax, xticklabels=axis_labels, yticklabels=axis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = fig.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"image/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from 0 to 61\n",
    "# 0,1,2,3,4,5,6,7,8,9,A...Z,a...Z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
